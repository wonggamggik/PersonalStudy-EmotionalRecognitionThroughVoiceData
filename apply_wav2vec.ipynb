{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "음성을 감정 분류 값으로 만드는 코드\n",
        "\n",
        "해당 모델은 코드를 벡터화 해서 감정분류까지 해주는 코드이다.\n",
        "\n",
        "별도의 k-wav2vec가 별도의 wav2vec은 추가로 적용해서 할 것"
      ],
      "metadata": {
        "id": "ec7TP-c-UCaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6_8BitbPO1x"
      },
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install regex==2024.11.6 \\\n",
        "numpy==1.26.4 \\\n",
        "setuptools==75.6.0 \\\n",
        "tokenizers==0.21.0 \\\n",
        "tqdm==4.67.1 \\\n",
        "transformers==4.47.0 \\\n",
        "librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from transformers import Wav2Vec2Processor\n",
        "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
        "    Wav2Vec2Model,\n",
        "    Wav2Vec2PreTrainedModel,\n",
        ")\n",
        "import torch.nn as nn\n",
        "import librosa"
      ],
      "metadata": {
        "id": "US8UXVh6PU3O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Head 정의\n",
        "# - 마지막 레이어의 임베딩을 입력받아 arousal, dominance, valence를 예측하기 위한 레이어\n",
        "class RegressionHead(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        # 은닉 벡터 크기: config.hidden_size\n",
        "        # 출력 레이어는 3차원 (arousal, dominance, valence)로 매핑\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.dropout = nn.Dropout(config.final_dropout)\n",
        "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        x = features\n",
        "        x = self.dropout(x)       # 드롭아웃: 과적합 방지\n",
        "        x = self.dense(x)         # 선형 변환\n",
        "        x = torch.tanh(x)         # 활성화 함수: tanh\n",
        "        x = self.dropout(x)       # 다시 드롭아웃\n",
        "        x = self.out_proj(x)      # 최종 출력층 -> 감정 값(3차원)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MFUh0Jg-PWAC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EmotionModel 정의\n",
        "# - Wav2Vec2 모델을 상속받아 Emotion Regression Head를 붙인 모델\n",
        "class EmotionModel(Wav2Vec2PreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "        # Pretrained Wav2Vec2 모델 불러오기\n",
        "        self.wav2vec2 = Wav2Vec2Model(config)\n",
        "        # 감정 예측 레이어\n",
        "        self.classifier = RegressionHead(config)\n",
        "        # 가중치 초기화\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_values):\n",
        "        # Wav2Vec2 모델에 입력: (batch, time)\n",
        "        outputs = self.wav2vec2(input_values)\n",
        "        # outputs[0]은 (batch, time, hidden_size) 형태의 last hidden states\n",
        "        hidden_states = outputs[0]\n",
        "\n",
        "        # 시간축에 대해 평균 풀링 -> (batch, hidden_size)\n",
        "        hidden_states = torch.mean(hidden_states, dim=1)\n",
        "\n",
        "        # 평균 풀링한 벡터를 Regression Head로 통과 -> (batch, 3)\n",
        "        logits = self.classifier(hidden_states)\n",
        "\n",
        "        # hidden_states: 임베딩, logits: 감정 예측값\n",
        "        return hidden_states, logits"
      ],
      "metadata": {
        "id": "rp0deVJrPXHj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디바이스 설정\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 모델 및 프로세서 로드\n",
        "# 사용 모델: audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
        "model_name = 'audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim'\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = EmotionModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "61eCAcSWPYkx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process_func 함수\n",
        "# 주어진 waveform과 샘플링 레이트를 받아 모델 추론을 수행하는 함수.\n",
        "# embeddings=True 시: hidden_states 반환\n",
        "# embeddings=False 시: logits 반환\n",
        "def process_func(waveform: np.ndarray, sampling_rate: int, embeddings: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    오디오 신호에 대해 Wav2Vec2 기반 감정 추론을 수행하는 함수.\n",
        "    Args:\n",
        "        waveform (np.ndarray): 오디오 신호 (shape: (1, samples))\n",
        "        sampling_rate (int): 오디오 샘플링 레이트 (예: 16kHz)\n",
        "        embeddings (bool): True면 임베딩(hidden_states) 반환, False면 예측 감정(logits) 반환\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 감정 예측값(배열) 또는 임베딩(배열)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Processor를 통해 입력값 전처리\n",
        "    #    return_tensors=\"pt\"로 파이토치 텐서 반환\n",
        "    inputs = processor(waveform, sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "    input_values = inputs[\"input_values\"].to(device)\n",
        "\n",
        "    # 2. 모델 추론 (no_grad로 백프로파게이션 비활성)\n",
        "    with torch.no_grad():\n",
        "        hidden_states, logits = model(input_values)\n",
        "\n",
        "    # 3. embeddings 파라미터에 따라 반환값 선택\n",
        "    output = hidden_states if embeddings else logits\n",
        "\n",
        "    # CPU로 이동한 뒤 numpy로 변환\n",
        "    return output.cpu().numpy()"
      ],
      "metadata": {
        "id": "RyZkoBNSRUQl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resample_audio 함수\n",
        "def resample_audio(filepath, target_sampling_rate=16000):\n",
        "    \"\"\"\n",
        "    오디오 파일을 지정된 샘플링 레이트로 변환합니다.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): 오디오 파일 경로\n",
        "        target_sampling_rate (int): 변환할 샘플링 레이트 (기본값: 16000)\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 변환된 오디오 데이터\n",
        "        int: 변환된 샘플링 레이트\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 원본 오디오 로드\n",
        "        waveform, original_sr = librosa.load(filepath, sr=None)\n",
        "        print(f\"Original sampling rate: {original_sr}\")\n",
        "\n",
        "        # 샘플링 레이트 변환\n",
        "        if original_sr != target_sampling_rate:\n",
        "            waveform = librosa.resample(waveform, orig_sr=original_sr, target_sr=target_sampling_rate)\n",
        "            print(f\"Resampled to {target_sampling_rate} Hz\")\n",
        "        else:\n",
        "            print(\"Sampling rate already matches the target rate.\")\n",
        "\n",
        "        return waveform, target_sampling_rate\n",
        "    except Exception as e:\n",
        "        print(f\"Error resampling {filepath}: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "1xocao31RX5C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze_all_files_with_resampling 함수\n",
        "def analyze_all_files_with_resampling(directory: str):\n",
        "    \"\"\"\n",
        "    지정된 디렉토리 내 모든 .wav 파일을 샘플링 레이트 변환 후 분석.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Directory '{directory}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "\n",
        "        if filename.lower().endswith(\".wav\"):\n",
        "            try:\n",
        "                print(f\"Processing file: {filename}\")\n",
        "\n",
        "                # 오디오 샘플링 레이트 변환\n",
        "                waveform, sr = resample_audio(filepath, target_sampling_rate=16000)\n",
        "                if waveform is None:\n",
        "                    continue\n",
        "\n",
        "                # 모델에 입력 형식으로 변환\n",
        "                waveform = waveform.reshape(1, -1).astype(np.float32)\n",
        "\n",
        "                # 감정 예측 수행\n",
        "                predictions = process_func(waveform, sr, embeddings=False)\n",
        "                print(f\"Predicted Arousal, Dominance, Valence for {filename}: {predictions[0]}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")"
      ],
      "metadata": {
        "id": "zRLT1EtNPaC8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 실행 부분\n",
        "if __name__ == \"__main__\":\n",
        "    # 분석할 디렉토리 이름 설정: 여기서는 \"voice\"\n",
        "    # voice 폴더 안에 .wav 파일들 넣어두기\n",
        "    directory = \"voice\"\n",
        "    analyze_all_files_with_resampling(directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H7haT-9Pbce",
        "outputId": "039934f2-c59d-4cc3-cd26-6bb9693efb91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: temp2.wav\n",
            "Original sampling rate: 48000\n",
            "Resampled to 16000 Hz\n",
            "Predicted Arousal, Dominance, Valence for temp2.wav: [0.36510953 0.43488592 0.51708657]\n",
            "Processing file: temp.wav\n",
            "Original sampling rate: 48000\n",
            "Resampled to 16000 Hz\n",
            "Predicted Arousal, Dominance, Valence for temp.wav: [0.5687486 0.5290034 0.5430766]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수치들을 3차원 값으로 보여주는 코드"
      ],
      "metadata": {
        "id": "xb8cK6V1T_SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh1UNgXvUqMG",
        "outputId": "04b66364-12cd-4458-e499-0daea5edd5f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def interactive_3d_plot(emotion_data, filenames):\n",
        "    \"\"\"\n",
        "    예측된 감정 값(Arousal, Dominance, Valence)을 대화형 3D 그래프로 시각화.\n",
        "\n",
        "    Args:\n",
        "        emotion_data (list of list): [[Arousal, Dominance, Valence], ...] 형식의 예측 값 리스트\n",
        "        filenames (list of str): 각 데이터에 해당하는 파일 이름 리스트\n",
        "    \"\"\"\n",
        "    # 예측 값 분리\n",
        "    arousal = [data[0] for data in emotion_data]\n",
        "    dominance = [data[1] for data in emotion_data]\n",
        "    valence = [data[2] for data in emotion_data]\n",
        "\n",
        "    # 3D 그래프 생성\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 데이터 추가\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=arousal,\n",
        "        y=dominance,\n",
        "        z=valence,\n",
        "        mode='markers+text',\n",
        "        marker=dict(\n",
        "            size=5,  # 점 크기 줄이기\n",
        "            color='blue',  # 점 색상\n",
        "            opacity=0.8\n",
        "        ),\n",
        "        text=filenames,  # 파일 이름 레이블\n",
        "        textposition=\"top center\"\n",
        "    ))\n",
        "\n",
        "    # 레이아웃 설정\n",
        "    fig.update_layout(\n",
        "        title='3D Emotion Graph',\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='Arousal', range=[0, 1]),  # X축 범위 0~1\n",
        "            yaxis=dict(title='Dominance', range=[0, 1]),  # Y축 범위 0~1\n",
        "            zaxis=dict(title='Valence', range=[0, 1]),  # Z축 범위 0~1\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=40)  # 그래프 여백 설정\n",
        "    )\n",
        "\n",
        "    # 그래프 표시\n",
        "    fig.show()\n",
        "\n",
        "# 예제 데이터\n",
        "emotion_predictions = [\n",
        "    [0.5687486, 0.5290034, 0.5430766],  # temp2.wav\n",
        "    [0.4568457, 0.6370042, 0.5901238],  # temp.wav\n",
        "]\n",
        "file_names = [\"temp2.wav\", \"temp.wav\"]\n",
        "\n",
        "# 대화형 3D 그래프 표시\n",
        "interactive_3d_plot(emotion_predictions, file_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "SOKTsgZTUSGM",
        "outputId": "25b1c112-b743-4d70-c0e5-28283cea2af3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3254b2bc-23ef-4076-a6b3-27d13ba6ded7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3254b2bc-23ef-4076-a6b3-27d13ba6ded7\")) {                    Plotly.newPlot(                        \"3254b2bc-23ef-4076-a6b3-27d13ba6ded7\",                        [{\"marker\":{\"color\":\"blue\",\"opacity\":0.8,\"size\":5},\"mode\":\"markers+text\",\"text\":[\"temp2.wav\",\"temp.wav\"],\"textposition\":\"top center\",\"x\":[0.5687486,0.4568457],\"y\":[0.5290034,0.6370042],\"z\":[0.5430766,0.5901238],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"Arousal\"},\"range\":[0,1]},\"yaxis\":{\"title\":{\"text\":\"Dominance\"},\"range\":[0,1]},\"zaxis\":{\"title\":{\"text\":\"Valence\"},\"range\":[0,1]}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":40},\"title\":{\"text\":\"3D Emotion Graph\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3254b2bc-23ef-4076-a6b3-27d13ba6ded7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "def cluster_and_plot_3d(emotion_data, filenames, n_clusters=3):\n",
        "    \"\"\"\n",
        "    감정 데이터에 대해 K-Means 군집화를 수행하고 결과를 3D 그래프로 시각화.\n",
        "\n",
        "    Args:\n",
        "        emotion_data (list of list): [[Arousal, Dominance, Valence], ...] 형식의 감정 값 리스트\n",
        "        filenames (list of str): 각 데이터에 해당하는 파일 이름 리스트\n",
        "        n_clusters (int): 생성할 군집의 수 (기본값: 3)\n",
        "    \"\"\"\n",
        "    # K-Means 클러스터링\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(emotion_data)\n",
        "\n",
        "    # 각 군집에 따른 색상 설정\n",
        "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
        "    cluster_colors = [colors[label] for label in cluster_labels]\n",
        "\n",
        "    # 예측 값 분리\n",
        "    arousal = [data[0] for data in emotion_data]\n",
        "    dominance = [data[1] for data in emotion_data]\n",
        "    valence = [data[2] for data in emotion_data]\n",
        "\n",
        "    # 3D 그래프 생성\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 데이터 추가\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=arousal,\n",
        "        y=dominance,\n",
        "        z=valence,\n",
        "        mode='markers+text',\n",
        "        marker=dict(\n",
        "            size=5,  # 점 크기\n",
        "            color=cluster_colors,  # 군집 색상\n",
        "            opacity=0.8\n",
        "        ),\n",
        "        text=filenames,  # 파일 이름 레이블\n",
        "        textposition=\"top center\"\n",
        "    ))\n",
        "\n",
        "    # 레이아웃 설정\n",
        "    fig.update_layout(\n",
        "        title=f'3D Emotion Graph with {n_clusters} Clusters',\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='Arousal', range=[0, 1]),\n",
        "            yaxis=dict(title='Dominance', range=[0, 1]),\n",
        "            zaxis=dict(title='Valence', range=[0, 1]),\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=40)\n",
        "    )\n",
        "\n",
        "    # 그래프 표시\n",
        "    fig.show()\n",
        "\n",
        "# 예제 데이터\n",
        "emotion_predictions = [\n",
        "    [0.5687486, 0.5290034, 0.5430766],  # temp2.wav\n",
        "    [0.4568457, 0.6370042, 0.5901238],  # temp.wav\n",
        "    [0.7238453, 0.4530021, 0.5201234],  # temp3.wav\n",
        "    [0.1234577, 0.2370043, 0.1901239],  # temp4.wav\n",
        "    [0.8234577, 0.8370043, 0.7901239],  # temp5.wav\n",
        "]\n",
        "file_names = [\"temp2.wav\", \"temp.wav\", \"temp3.wav\", \"temp4.wav\", \"temp5.wav\"]\n",
        "\n",
        "# 군집화 및 시각화\n",
        "cluster_and_plot_3d(emotion_predictions, file_names, n_clusters=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8-n_JOHBVKVr",
        "outputId": "2ebc428a-21c5-4c5e-bcf7-9e855444dbee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7c1e86f5-ce72-4193-8aa2-620ea79fc00a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7c1e86f5-ce72-4193-8aa2-620ea79fc00a\")) {                    Plotly.newPlot(                        \"7c1e86f5-ce72-4193-8aa2-620ea79fc00a\",                        [{\"marker\":{\"color\":[\"green\",\"red\",\"green\",\"blue\",\"red\"],\"opacity\":0.8,\"size\":5},\"mode\":\"markers+text\",\"text\":[\"temp2.wav\",\"temp.wav\",\"temp3.wav\",\"temp4.wav\",\"temp5.wav\"],\"textposition\":\"top center\",\"x\":[0.5687486,0.4568457,0.7238453,0.1234577,0.8234577],\"y\":[0.5290034,0.6370042,0.4530021,0.2370043,0.8370043],\"z\":[0.5430766,0.5901238,0.5201234,0.1901239,0.7901239],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"Arousal\"},\"range\":[0,1]},\"yaxis\":{\"title\":{\"text\":\"Dominance\"},\"range\":[0,1]},\"zaxis\":{\"title\":{\"text\":\"Valence\"},\"range\":[0,1]}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":40},\"title\":{\"text\":\"3D Emotion Graph with 3 Clusters\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7c1e86f5-ce72-4193-8aa2-620ea79fc00a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}